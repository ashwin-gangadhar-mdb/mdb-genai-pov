{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1da35373",
   "metadata": {},
   "source": [
    "## Import Transformer\n",
    "\n",
    "First we'll import our pre-trained sentence similarity model. This one was trained using BERT techniques on a massive set of tuples from the internet. Tuples take the form of input-output. So for example, an input could be a question, and an output could be an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d206ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: scipy in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: numpy in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: sentencepiece in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: tqdm in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: nltk in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: requests in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: fsspec in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.7.1)\n",
      "Requirement already satisfied: filelock in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: click in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashwin.gangadhar/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9428196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe309872",
   "metadata": {},
   "source": [
    "## Prepare Corpus\n",
    "\n",
    "We are going to pull the summary from the <a href=\"https://en.wikipedia.org/wiki/Japan\">Japan Wikipedia Page</a>, then prepare it for vector embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3089ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan is an island country in East Asia\n",
      " It is situated in the northwest Pacific Ocean, and is bordered on the west by the Sea of Japan, while extending from the Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south\n",
      " Japan is a part of the Ring of Fire, and spans an archipelago of 6852 islands covering 377,975 square kilometers (145,937 sq mi); the five main islands are Hokkaido, Honshu, Shikoku, Kyushu, and Okinawa\n",
      " Tokyo is the nation's capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto\n",
      " Japan is the eleventh most populous country in the world, as well as one of the most densely populated and urbanized\n",
      " About three-fourths of the country's terrain is mountainous, concentrating its population of 125\n",
      "5 million on narrow coastal plains\n",
      " Japan is divided into 47 administrative prefectures and eight traditional regions\n",
      " The Greater Tokyo Area is the most populous metropolitan area in the world, with more than 37\n",
      "4 million residents\n",
      " Japan has been inhabited since the Upper Paleolithic period (30,000 BC), though the first written mention of the archipelago appears in a Chinese chronicle (the Book of Han) finished in the 2nd century AD\n",
      " Between the 4th and 9th centuries, the kingdoms of Japan became unified under an emperor and the imperial court based in Heian-kyō\n",
      " Beginning in the 12th century, political power was held by a series of military dictators (shōgun) and feudal lords (daimyō) and enforced by a class of warrior nobility (samurai)\n",
      " After a century-long period of civil war, the country was reunified in 1603 under the Tokugawa shogunate, which enacted an isolationist foreign policy\n",
      " In 1854, a United States fleet forced Japan to open trade to the West, which led to the end of the shogunate and the restoration of imperial power in 1868\n",
      " In the Meiji period, the Empire of Japan adopted a Western-modeled constitution and pursued a program of industrialization and modernization\n",
      " Amidst a rise in militarism and overseas colonization, Japan invaded China in 1937 and entered World War II as an Axis power in 1941\n",
      " After suffering defeat in the Pacific War and two atomic bombings, Japan surrendered in 1945 and came under a seven-year Allied occupation, during which it adopted a new constitution and began a military alliance with the United States\n",
      " Under the 1947 constitution, Japan has maintained a unitary parliamentary constitutional monarchy with a bicameral legislature, the National Diet\n",
      " Japan is a highly developed country, and a great power in global politics\n",
      " Its economy is the world's third-largest by nominal GDP and the fourth-largest by PPP\n",
      " Although Japan has renounced its right to declare war, the country maintains Self-Defense Forces that rank as one of the world's strongest militaries\n",
      " After World War II, Japan experienced record growth in an economic miracle, becoming the second-largest economy in the world by 1972 but has stagnated since 1995 in what is referred to as the Lost Decades\n",
      " Japan has the world's highest life expectancy, though it is experiencing a decline in population\n",
      " A global leader in the automotive, robotics and electronics industries, the country has made significant contributions to science and technology\n",
      " The culture of Japan is well known around the world, including its art, cuisine, music, and popular culture, which encompasses prominent comic, animation and video game industries\n",
      " It is a member of numerous international organizations, including the United Nations (since 1956), OECD, G20 and Group of Seven\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set corpus from first page of wikipedia\n",
    "corpus = \"Japan is an island country in East Asia. It is situated in the northwest Pacific Ocean, and is bordered on the west by the Sea of Japan, while extending from the Sea of Okhotsk in the north toward the East China Sea, Philippine Sea, and Taiwan in the south. Japan is a part of the Ring of Fire, and spans an archipelago of 6852 islands covering 377,975 square kilometers (145,937 sq mi); the five main islands are Hokkaido, Honshu, Shikoku, Kyushu, and Okinawa. Tokyo is the nation's capital and largest city, followed by Yokohama, Osaka, Nagoya, Sapporo, Fukuoka, Kobe, and Kyoto. Japan is the eleventh most populous country in the world, as well as one of the most densely populated and urbanized. About three-fourths of the country's terrain is mountainous, concentrating its population of 125.5 million on narrow coastal plains. Japan is divided into 47 administrative prefectures and eight traditional regions. The Greater Tokyo Area is the most populous metropolitan area in the world, with more than 37.4 million residents. Japan has been inhabited since the Upper Paleolithic period (30,000 BC), though the first written mention of the archipelago appears in a Chinese chronicle (the Book of Han) finished in the 2nd century AD. Between the 4th and 9th centuries, the kingdoms of Japan became unified under an emperor and the imperial court based in Heian-kyō. Beginning in the 12th century, political power was held by a series of military dictators (shōgun) and feudal lords (daimyō) and enforced by a class of warrior nobility (samurai). After a century-long period of civil war, the country was reunified in 1603 under the Tokugawa shogunate, which enacted an isolationist foreign policy. In 1854, a United States fleet forced Japan to open trade to the West, which led to the end of the shogunate and the restoration of imperial power in 1868. In the Meiji period, the Empire of Japan adopted a Western-modeled constitution and pursued a program of industrialization and modernization. Amidst a rise in militarism and overseas colonization, Japan invaded China in 1937 and entered World War II as an Axis power in 1941. After suffering defeat in the Pacific War and two atomic bombings, Japan surrendered in 1945 and came under a seven-year Allied occupation, during which it adopted a new constitution and began a military alliance with the United States. Under the 1947 constitution, Japan has maintained a unitary parliamentary constitutional monarchy with a bicameral legislature, the National Diet. Japan is a highly developed country, and a great power in global politics. Its economy is the world's third-largest by nominal GDP and the fourth-largest by PPP. Although Japan has renounced its right to declare war, the country maintains Self-Defense Forces that rank as one of the world's strongest militaries. After World War II, Japan experienced record growth in an economic miracle, becoming the second-largest economy in the world by 1972 but has stagnated since 1995 in what is referred to as the Lost Decades. Japan has the world's highest life expectancy, though it is experiencing a decline in population. A global leader in the automotive, robotics and electronics industries, the country has made significant contributions to science and technology. The culture of Japan is well known around the world, including its art, cuisine, music, and popular culture, which encompasses prominent comic, animation and video game industries. It is a member of numerous international organizations, including the United Nations (since 1956), OECD, G20 and Group of Seven.\"\n",
    "# turn it into an array of sentences\n",
    "docs = corpus.split('.')\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1725e6e4",
   "metadata": {},
   "source": [
    "## Encode Corpus\n",
    "encode each array (sentence) into a 384 dimension vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5605b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vector: 384\n",
      "[[ 0.05527085  0.04808538 -0.00781386 ... -0.01564413 -0.05199257\n",
      "  -0.02691225]\n",
      " [ 0.07182306  0.11629469  0.03326562 ...  0.00400932 -0.0403082\n",
      "   0.09569602]\n",
      " [ 0.11922325  0.00596009 -0.01733767 ...  0.02097983 -0.07156345\n",
      "   0.0195329 ]\n",
      " ...\n",
      " [ 0.07631288 -0.05397936 -0.02969839 ... -0.03893653  0.0111805\n",
      "   0.04070463]\n",
      " [-0.02801095 -0.03043353  0.00067352 ... -0.08902533 -0.00195529\n",
      "   0.02784133]\n",
      " [-0.11883838  0.04829862 -0.00254809 ...  0.12640943  0.04654909\n",
      "  -0.01571736]]\n"
     ]
    }
   ],
   "source": [
    "corpus_vector = model.encode(docs)\n",
    "print(\"Length of vector:\", len(corpus_vector[0]))\n",
    "\n",
    "print(corpus_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b990b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_vector)\n",
    "corpus_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b2b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "MONGO_CONN = 'mongodb+srv://<username>:<password>@retail-demo.2wqno.mongodb.net/?retryWrites=true&w=majority'\n",
    "client = MongoClient(MONGO_CONN)\n",
    "\n",
    "col = client['sample']['vectest']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c99b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2a103b430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(map(lambda x:{x[0]:x[1].tolist(), \"doc\":x[2]},zip([\"d\"]*28, corpus_vector, docs)))\n",
    "\n",
    "col.delete_many({})\n",
    "col.insert_many(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f932655",
   "metadata": {},
   "source": [
    "## Embed Our Query\n",
    "\n",
    "We then take an english-intuitive question, also send that through the same 384 dimension calculation and then the resulting vector query and corpus query are sent through the `calculate` function, where the most similar strings are calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48b7cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.96888566e-02 -2.07897052e-02  1.02820890e-02 -1.01067137e-03\n",
      " -2.72650030e-02 -9.10138488e-02 -2.13078246e-03  3.08536552e-02\n",
      " -3.66504081e-02 -3.39046009e-02  7.94383362e-02 -8.56574848e-02\n",
      " -3.01053412e-02  9.26302001e-02  6.57289997e-02 -6.67824522e-02\n",
      " -7.48174936e-02 -1.02015361e-02 -2.52876468e-02 -4.20919806e-02\n",
      "  2.02686386e-03 -4.83456105e-02  5.34150153e-02 -1.70314442e-02\n",
      "  4.72873896e-02  2.20477302e-02  5.00186831e-02  1.35236857e-02\n",
      "  3.43261473e-02 -2.62602512e-03 -6.16401024e-02  4.52699810e-02\n",
      "  1.01693496e-01  1.86019503e-02  3.19578610e-02 -1.40755596e-02\n",
      "  2.36791652e-02  2.71681976e-02  2.40688622e-02 -2.27920897e-02\n",
      " -7.36001655e-02  3.87528837e-02  7.09293708e-02 -1.67964713e-03\n",
      "  4.17525433e-02  3.42302881e-02 -2.38649156e-02 -1.88812744e-02\n",
      "  1.26917008e-02 -3.04418206e-02  6.48808256e-02 -1.91413984e-02\n",
      " -2.29218677e-02  1.19591087e-01  4.47782427e-02  1.92081649e-02\n",
      "  9.12994891e-03  4.85389307e-03 -3.98185998e-02  7.66239092e-02\n",
      " -5.01065329e-02 -6.45835400e-02  7.20108161e-04 -2.95846350e-02\n",
      "  5.78792989e-02 -1.15427445e-03 -5.39694987e-02 -8.87506176e-03\n",
      " -8.78599957e-02 -7.42227733e-02  4.73343432e-02  7.88388588e-03\n",
      "  4.52965051e-02  2.25307029e-02 -7.82059282e-02 -7.75991306e-02\n",
      " -6.60645738e-02  5.68952709e-02 -2.94812042e-02 -5.42261079e-02\n",
      "  9.05832462e-03  7.47874230e-02  1.47606162e-02 -9.17285739e-04\n",
      "  4.14368063e-02 -1.68634746e-02  1.09170983e-02 -1.19690806e-01\n",
      " -3.35766189e-02  7.39935786e-02 -8.25821143e-03  5.90851419e-02\n",
      "  1.37642980e-01 -2.45420448e-02 -5.58414906e-02  1.20337261e-02\n",
      " -3.53393820e-03 -2.08155755e-02  2.55578980e-02  2.34313942e-02\n",
      "  4.02555382e-03 -2.38720700e-02  8.34096670e-02 -1.06405737e-02\n",
      " -6.17946461e-02  5.69861941e-03 -1.00441705e-02  2.34619044e-02\n",
      "  3.15406360e-02  5.12657352e-02 -6.21576011e-02 -2.02208236e-02\n",
      " -6.66669160e-02 -6.99623069e-03  3.32099013e-02 -6.60764202e-02\n",
      "  7.48578086e-02  5.19979298e-02  9.37542506e-03  8.02606419e-02\n",
      " -1.70618631e-02 -5.62606677e-02  4.72386666e-02  1.75942015e-02\n",
      "  7.29372948e-02  7.90778026e-02 -7.00783879e-02 -3.32979824e-33\n",
      "  7.00027421e-02 -6.98950738e-02  1.29071418e-02  1.20373733e-01\n",
      " -6.63775429e-02 -1.11379502e-02  1.33392382e-02 -9.68066510e-04\n",
      " -1.82257760e-02 -6.70593698e-03 -1.44141577e-02  5.24152592e-02\n",
      " -1.79193262e-02 -4.95391525e-02  1.54110044e-01 -4.04386374e-04\n",
      " -5.31381592e-02  8.00384134e-02  1.22295292e-02  2.96988841e-02\n",
      "  4.84812912e-03  4.12305817e-02 -1.96613409e-02 -3.44438776e-02\n",
      " -4.79669049e-02 -1.43860318e-02 -3.34342755e-02 -8.73005297e-03\n",
      " -2.76502091e-02  3.44329141e-02 -8.19147658e-03 -2.46541686e-02\n",
      " -6.65397868e-02 -2.12090891e-02  2.07216851e-02  9.54305811e-04\n",
      "  3.57528664e-02  9.68252402e-03  5.10066468e-03 -1.08387582e-02\n",
      " -4.40795757e-02 -1.07224196e-01 -1.19187310e-02 -1.04186656e-02\n",
      "  6.61704615e-02 -2.30526850e-02  3.53928022e-02 -1.72023270e-02\n",
      "  2.51219925e-02  9.08706486e-02 -7.95856416e-02 -1.16833276e-03\n",
      "  7.92463869e-02 -2.82012820e-02  6.47270009e-02  2.77933083e-03\n",
      "  5.88695630e-02 -1.77633468e-04  2.93333698e-02  9.31339636e-02\n",
      " -5.11448421e-02  7.36591667e-02 -5.73821999e-02  5.03839031e-02\n",
      "  9.65327118e-03  4.58881930e-02 -4.58524656e-03 -4.15090136e-02\n",
      " -2.81564649e-02 -7.63581321e-03 -2.32822653e-02 -6.63278112e-03\n",
      "  1.61498934e-02  1.10242084e-01 -9.04507339e-02 -4.25495803e-02\n",
      " -6.16239607e-02  3.32652442e-02 -6.51450381e-02 -8.41791555e-03\n",
      " -1.02542490e-01 -3.04076057e-02 -5.98039106e-02  5.78486472e-02\n",
      "  9.22445729e-02  6.41788766e-02  5.38692437e-02  4.22421424e-03\n",
      " -1.96974464e-02 -5.24669103e-02 -4.25958522e-02 -3.56742665e-02\n",
      "  7.13742822e-02 -2.50943080e-02 -2.19505206e-02  1.77070977e-33\n",
      "  1.58152077e-02  4.14766148e-02 -3.97160314e-02 -6.85178041e-02\n",
      " -3.86794657e-02 -1.00823911e-02  1.54131847e-02  8.70006830e-02\n",
      " -7.14660957e-02 -2.63143256e-02 -6.43160045e-02  1.35407411e-02\n",
      "  7.11262152e-02  4.99773882e-02 -1.55311767e-02 -9.40266647e-04\n",
      "  4.37886529e-02  4.64503467e-02  3.05416528e-02 -2.54735649e-02\n",
      " -2.29772720e-02 -8.29957128e-02 -5.55784442e-03  7.40475431e-02\n",
      " -5.99642769e-02  3.30485404e-02 -3.82496789e-02 -1.60401892e-02\n",
      " -3.50191109e-02  6.73835501e-02  2.99825985e-03 -1.45624563e-01\n",
      " -4.22385037e-02 -1.74061991e-02 -1.15956493e-01 -1.64811894e-01\n",
      " -3.90295088e-02 -1.42367035e-02  1.64703224e-02  2.13992242e-02\n",
      " -4.35910076e-02 -6.09250553e-02  4.77955956e-03  9.89470407e-02\n",
      " -9.99946743e-02  1.43115669e-02  2.61464175e-02  9.88870710e-02\n",
      " -1.02328204e-01 -3.90191451e-02 -1.83735304e-02  3.13121527e-02\n",
      "  4.22501527e-02 -2.23288424e-02 -4.43805717e-02 -3.65035832e-02\n",
      " -2.40154509e-02  1.03923596e-01 -1.52705479e-02  1.67974476e-02\n",
      "  7.12381974e-02 -8.02310929e-03  2.95001641e-02  5.30532412e-02\n",
      "  2.07841843e-02 -1.25236316e-02  1.11696996e-01  3.88057344e-02\n",
      "  2.35453937e-02  1.19431922e-02  2.07836032e-02 -1.20698186e-02\n",
      " -2.33934205e-02  1.49328792e-02  5.76321743e-02  3.24024223e-02\n",
      "  3.47787440e-02  5.86614618e-03  8.73413831e-02  1.23774689e-02\n",
      " -6.21697418e-02  8.06632917e-03 -2.98214667e-02 -7.80563802e-02\n",
      " -2.54046582e-02  2.03004610e-02  1.03387823e-02 -6.65619522e-02\n",
      "  4.87603731e-02 -3.90767455e-02 -4.77157868e-02  3.48670557e-02\n",
      "  2.35884618e-02 -9.52158682e-03 -3.56312916e-02 -1.59147433e-08\n",
      "  4.07906510e-02 -8.27094018e-02 -1.16887083e-02 -4.45564501e-02\n",
      " -3.34439706e-03  1.10779358e-02 -5.66113591e-02  5.23048416e-02\n",
      "  4.06755805e-02  3.14269029e-02  1.18321240e-01  6.34292588e-02\n",
      " -4.64849025e-02 -1.06577734e-02 -2.51137689e-02 -9.74086076e-02\n",
      "  2.48623881e-02  1.49791434e-01 -3.07381600e-02 -1.54537018e-02\n",
      "  4.88761663e-02 -3.77837680e-02  2.30062958e-02 -5.42329215e-02\n",
      "  5.65398447e-02 -1.55023178e-02 -2.00843904e-02  7.27840886e-02\n",
      " -4.23252434e-02  1.55665400e-03  1.15889348e-02 -4.90413085e-02\n",
      " -1.66140907e-02  5.23240566e-02  1.06170373e-02 -7.64922239e-03\n",
      " -4.99028340e-02 -2.27934700e-02 -7.26739243e-02 -1.12392418e-01\n",
      "  2.97069866e-02 -5.78452908e-02  4.60152030e-02  4.07178476e-02\n",
      "  3.84053998e-02  1.19808298e-02  1.48868598e-02  6.03693128e-02\n",
      "  5.10139242e-02 -1.01081938e-01 -9.26967412e-02  4.82835919e-02\n",
      " -4.97421995e-02  2.86205066e-03 -2.66494639e-02 -1.28755420e-02\n",
      "  5.61931245e-02 -7.76265711e-02  2.33772043e-02  6.04561456e-02\n",
      " -4.57017304e-04  5.40445372e-03 -6.42071590e-02 -1.05517323e-03]\n"
     ]
    }
   ],
   "source": [
    "# Encode our question and documents in 384 dimension\n",
    "\n",
    "# query = \"How many islands are comprised of Japan?\"\n",
    "# query = \"Name a few major cities in japan?\"\n",
    "# query = \"Which constitution model did Japan adopt?\"\n",
    "# query = \"Which are the important cities in japan?\"\n",
    "query = \"Japan is divided into how many administrative regions?\"\n",
    "query_vector = model.encode(query)\n",
    "print(query_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53414d6e",
   "metadata": {},
   "source": [
    "## Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a1969cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashwin.gangadhar/projects/vector-search/use-cases/question-and-answering/Question and Answering.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin.gangadhar/projects/vector-search/use-cases/question-and-answering/Question%20and%20Answering.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate cosine similarity between the corpus of vectors and the query vector\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwin.gangadhar/projects/vector-search/use-cases/question-and-answering/Question%20and%20Answering.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mcos_sim(query_vector, corpus_vector)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin.gangadhar/projects/vector-search/use-cases/question-and-answering/Question%20and%20Answering.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Combine docs & scores\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin.gangadhar/projects/vector-search/use-cases/question-and-answering/Question%20and%20Answering.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m doc_score_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(docs, scores))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_vector' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between the corpus of vectors and the query vector\n",
    "scores = util.cos_sim(query_vector, corpus_vector)[0].cpu().tolist()\n",
    "\n",
    "# Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49e8dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Japan is divided into 47 administrative prefectures and eight traditional regions\t score:0.9407361149787903\n",
      "Japan is an island country in East Asia\t score:0.8376696705818176\n",
      " Japan is a part of the Ring of Fire, and spans an archipelago of 6852 islands covering 377,975 square kilometers (145,937 sq mi); the five main islands are Hokkaido, Honshu, Shikoku, Kyushu, and Okinawa\t score:0.8008524179458618\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\n",
    "  \"$search\": {\n",
    "    \"index\": \"default\",\n",
    "    \"knnBeta\": {\n",
    "      \"vector\": query_vector.tolist(),\n",
    "      \"path\": \"d\",\n",
    "      # \"filter\":{\n",
    "      #           \"phrase\": {\n",
    "      #             \"path\": \"doc\",\n",
    "      #             \"query\": \"capital\",\n",
    "      #           }\n",
    "      #         },\n",
    "      \"k\": 3\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\"$project\":{\n",
    "    \"score\":{\n",
    "              '$meta': 'searchScore'\n",
    "            },\n",
    "    \"doc\":1,\n",
    "    \"_id\": 0\n",
    "}}]\n",
    "res = list(col.aggregate(pipeline))\n",
    "context = \"\"\n",
    "for i in res:\n",
    "    context += \". \"+i['doc']\n",
    "    print(i['doc'] + \"\\t score:\"+ str(i['score']) )\n",
    "instruction=\"Answer is present in the context\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d17ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/ashwin.gangadhar/projects/llma/llama.cpp/models/alpaca/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.07 MB\n",
      "llama_model_load_internal: mem required  = 5439.94 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# You can avoid running this cell each time\n",
    "# Creating a promt template to query\n",
    "\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context and adhering to instruciton. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with 'I don't know'.\n",
    "### Context : {context}\n",
    "\n",
    "### Question: {question}\n",
    "\n",
    "### Instruction : {instruction}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\",\"instruction\"])\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"/Users/ashwin.gangadhar/projects/llma/llama.cpp/models/alpaca/ggml-model-q4_0.bin\", callback_manager=callback_manager, verbose=True\n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dea76f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2263.57 ms\n",
      "llama_print_timings:      sample time =     2.14 ms /     3 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
      "llama_print_timings: prompt eval time = 10413.60 ms /   182 tokens (   57.22 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =    99.87 ms /     2 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_print_timings:       total time = 10551.53 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'47'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run({\"question\":query,\"context\":context,\"instruction\": instruction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
